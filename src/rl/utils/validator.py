"""
å…¼å®¹æ€§éªŒè¯å™¨
Compatibility Validator

éªŒè¯ç¯å¢ƒåŒ…è£…å™¨ä¸è®­ç»ƒå™¨çš„å…¼å®¹æ€§
"""

import sys
import logging
import numpy as np
import torch
from pathlib import Path
from typing import Dict, Any, Tuple, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from src.env.wind_farm_env import WindFarmParallelEnv
from src.rl.env_wrappers import create_wrapped_env
from src.rl.mappo_trainer import MAPPOTrainer

logger = logging.getLogger(__name__)


class CompatibilityValidator:
    """å…¼å®¹æ€§éªŒè¯å™¨"""
    
    def __init__(self, config_path: str = "config.yaml"):
        """
        åˆå§‹åŒ–éªŒè¯å™¨
        
        Args:
            config_path: ç¯å¢ƒé…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config_path = config_path
        self.validation_results = {}
        
        logger.info(f"CompatibilityValidatoråˆå§‹åŒ–: {config_path}")
    
    def validate_environment_wrappers(self) -> bool:
        """éªŒè¯ç¯å¢ƒåŒ…è£…å™¨å…¼å®¹æ€§"""
        logger.info("å¼€å§‹éªŒè¯ç¯å¢ƒåŒ…è£…å™¨å…¼å®¹æ€§")
        
        try:
            # 1. åˆ›å»ºåŸå§‹ç¯å¢ƒ
            base_env = WindFarmParallelEnv(
                config_path=self.config_path,
                layers_path="layers.pkl", 
                cache_dir="cache"
            )
            
            # 2. åˆ›å»ºåŒ…è£…ç¯å¢ƒ
            env_config = {
                "env_config": {
                    "config_path": self.config_path,
                    "layers_path": "layers.pkl",
                    "cache_dir": "cache"
                },
                "use_obs_norm": True,
                "use_action_masking": True
            }
            wrapped_env = create_wrapped_env(env_config)
            
            # 3. éªŒè¯ç¯å¢ƒå±æ€§
            assert hasattr(wrapped_env, 'agents'), "åŒ…è£…ç¯å¢ƒç¼ºå°‘agentså±æ€§"
            assert hasattr(wrapped_env, 'observation_space'), "åŒ…è£…ç¯å¢ƒç¼ºå°‘observation_spaceå±æ€§"
            assert hasattr(wrapped_env, 'action_space'), "åŒ…è£…ç¯å¢ƒç¼ºå°‘action_spaceå±æ€§"
            
            # 4. éªŒè¯æ™ºèƒ½ä½“ä¸€è‡´æ€§
            base_agents = set(base_env.agents)  # agentså±æ€§å·²ç»æ˜¯IDåˆ—è¡¨
            wrapped_agents = set(wrapped_env.agents)  # agentså±æ€§å·²ç»æ˜¯IDåˆ—è¡¨
            assert base_agents == wrapped_agents, f"æ™ºèƒ½ä½“ä¸ä¸€è‡´: {base_agents} vs {wrapped_agents}"
            
            # 5. éªŒè¯resetæ¥å£
            base_obs, base_info = base_env.reset()
            wrap_obs, wrap_info = wrapped_env.reset()
            
            # éªŒè¯æ™ºèƒ½ä½“æ•°é‡ä¸€è‡´
            assert set(base_obs.keys()) == set(wrap_obs.keys()), "resetè¿”å›çš„æ™ºèƒ½ä½“ä¸ä¸€è‡´"
            
            # 6. éªŒè¯è§‚æµ‹æ ¼å¼
            for agent_id in base_obs:
                if isinstance(wrap_obs[agent_id], dict):
                    # ActionMaskingAdapterçš„è¾“å‡ºæ ¼å¼
                    assert "obs" in wrap_obs[agent_id], f"æ™ºèƒ½ä½“{agent_id}ç¼ºå°‘obså­—æ®µ"
                    assert "action_mask" in wrap_obs[agent_id], f"æ™ºèƒ½ä½“{agent_id}ç¼ºå°‘action_maskå­—æ®µ"
                    
                    # éªŒè¯è§‚æµ‹ç»´åº¦
                    base_shape = base_obs[agent_id].shape
                    wrap_shape = wrap_obs[agent_id]["obs"].shape
                    assert base_shape == wrap_shape, f"è§‚æµ‹ç»´åº¦ä¸åŒ¹é…: {base_shape} vs {wrap_shape}"
                    
                    # éªŒè¯åŠ¨ä½œæ©ç ç»´åº¦
                    mask_shape = wrap_obs[agent_id]["action_mask"].shape
                    expected_mask_shape = (base_env.action_space.n,)
                    assert mask_shape == expected_mask_shape, f"åŠ¨ä½œæ©ç ç»´åº¦ä¸åŒ¹é…: {mask_shape} vs {expected_mask_shape}"
            
            # 7. éªŒè¯å…¨å±€çŠ¶æ€
            first_agent = list(wrap_info.keys())[0]
            assert "global_state" in wrap_info[first_agent], "ç¼ºå°‘å…¨å±€çŠ¶æ€"
            global_state = wrap_info[first_agent]["global_state"]
            assert isinstance(global_state, np.ndarray), "å…¨å±€çŠ¶æ€ä¸æ˜¯numpyæ•°ç»„"
            assert global_state.ndim == 1, "å…¨å±€çŠ¶æ€åº”è¯¥æ˜¯ä¸€ç»´æ•°ç»„"
            
            # 8. éªŒè¯stepæ¥å£
            actions = {agent_id: 0 for agent_id in base_agents}  # ä½¿ç”¨STAYåŠ¨ä½œ
            
            base_step_result = base_env.step(actions)
            wrap_step_result = wrapped_env.step(actions)
            
            assert len(base_step_result) == 5, "åŸºç¡€ç¯å¢ƒstepè¿”å›å€¼ä¸æ˜¯5å…ƒç»„"
            assert len(wrap_step_result) == 5, "åŒ…è£…ç¯å¢ƒstepè¿”å›å€¼ä¸æ˜¯5å…ƒç»„"
            
            # éªŒè¯è¿”å›å€¼ç±»å‹
            wrap_obs, wrap_rewards, wrap_dones, wrap_truncated, wrap_infos = wrap_step_result
            
            for agent_id in wrap_obs:
                assert isinstance(wrap_obs[agent_id], dict), f"æ™ºèƒ½ä½“{agent_id}è§‚æµ‹ä¸æ˜¯å­—å…¸æ ¼å¼"
                assert "global_state" in wrap_infos[agent_id], f"æ™ºèƒ½ä½“{agent_id}ç¼ºå°‘å…¨å±€çŠ¶æ€"
            
            self.validation_results['environment_wrappers'] = True
            logger.info("âœ“ ç¯å¢ƒåŒ…è£…å™¨å…¼å®¹æ€§éªŒè¯é€šè¿‡")
            return True
            
        except Exception as e:
            self.validation_results['environment_wrappers'] = False
            logger.error(f"âœ— ç¯å¢ƒåŒ…è£…å™¨å…¼å®¹æ€§éªŒè¯å¤±è´¥: {e}")
            return False
    
    def validate_data_flow(self) -> bool:
        """éªŒè¯æ•°æ®æµæ­£ç¡®æ€§"""
        logger.info("å¼€å§‹éªŒè¯æ•°æ®æµæ­£ç¡®æ€§")
        
        try:
            # åˆ›å»ºåŒ…è£…ç¯å¢ƒ
            env_config = {
                "env_config": {
                    "config_path": self.config_path,
                    "layers_path": "layers.pkl",
                    "cache_dir": "cache"
                },
                "use_obs_norm": True,
                "use_action_masking": True
            }
            env = create_wrapped_env(env_config)
            
            # é‡ç½®ç¯å¢ƒ
            obs, infos = env.reset()
            
            # éªŒè¯æ•°æ®æ ¼å¼ä¸€è‡´æ€§
            for step in range(10):
                # æ„é€ éšæœºåŠ¨ä½œï¼ˆç¡®ä¿ä½¿ç”¨å¯è¡ŒåŠ¨ä½œï¼‰
                actions = {}
                for agent_id in obs:
                    action_mask = obs[agent_id]["action_mask"]
                    valid_actions = np.where(action_mask)[0]
                    if len(valid_actions) > 0:
                        actions[agent_id] = int(np.random.choice(valid_actions))
                    else:
                        actions[agent_id] = env.action_space.n - 1  # STAYåŠ¨ä½œ
                
                # ç¯å¢ƒæ­¥è¿›
                next_obs, rewards, dones, truncated, next_infos = env.step(actions)
                
                # éªŒè¯æ•°æ®ç±»å‹
                for agent_id in next_obs:
                    assert isinstance(next_obs[agent_id], dict), "è§‚æµ‹ä¸æ˜¯å­—å…¸æ ¼å¼"
                    assert isinstance(rewards[agent_id], (int, float)), "å¥–åŠ±ä¸æ˜¯æ•°å€¼ç±»å‹"
                    assert isinstance(dones[agent_id], bool), "doneä¸æ˜¯å¸ƒå°”ç±»å‹"
                    assert isinstance(next_infos[agent_id], dict), "infoä¸æ˜¯å­—å…¸æ ¼å¼"
                    
                    # éªŒè¯è§‚æµ‹å­—æ®µ
                    assert "obs" in next_obs[agent_id], "ç¼ºå°‘obså­—æ®µ"
                    assert "action_mask" in next_obs[agent_id], "ç¼ºå°‘action_maskå­—æ®µ"
                    assert "global_state" in next_infos[agent_id], "ç¼ºå°‘global_stateå­—æ®µ"
                    
                    # éªŒè¯æ•°æ®ç»´åº¦
                    obs_array = next_obs[agent_id]["obs"]
                    mask_array = next_obs[agent_id]["action_mask"]
                    global_state_array = next_infos[agent_id]["global_state"]
                    
                    assert obs_array.ndim == 1, "è§‚æµ‹åº”è¯¥æ˜¯ä¸€ç»´æ•°ç»„"
                    assert mask_array.ndim == 1, "åŠ¨ä½œæ©ç åº”è¯¥æ˜¯ä¸€ç»´æ•°ç»„"
                    assert global_state_array.ndim == 1, "å…¨å±€çŠ¶æ€åº”è¯¥æ˜¯ä¸€ç»´æ•°ç»„"
                    
                    # éªŒè¯åŠ¨ä½œæ©ç æœ‰æ•ˆæ€§
                    assert mask_array.dtype == bool, "åŠ¨ä½œæ©ç åº”è¯¥æ˜¯å¸ƒå°”æ•°ç»„"
                    assert np.any(mask_array), "åŠ¨ä½œæ©ç è‡³å°‘åº”æœ‰ä¸€ä¸ªå¯è¡ŒåŠ¨ä½œ"
                
                # æ›´æ–°è§‚æµ‹
                obs = next_obs
                infos = next_infos
                
                # å¦‚æœå›åˆç»“æŸï¼Œé‡ç½®ç¯å¢ƒ
                if any(dones.values()):
                    obs, infos = env.reset()
            
            self.validation_results['data_flow'] = True
            logger.info("âœ“ æ•°æ®æµæ­£ç¡®æ€§éªŒè¯é€šè¿‡")
            return True
            
        except Exception as e:
            self.validation_results['data_flow'] = False
            logger.error(f"âœ— æ•°æ®æµæ­£ç¡®æ€§éªŒè¯å¤±è´¥: {e}")
            return False
    
    def validate_training_integration(self) -> bool:
        """éªŒè¯è®­ç»ƒå™¨é›†æˆ"""
        logger.info("å¼€å§‹éªŒè¯è®­ç»ƒå™¨é›†æˆ")
        
        try:
            # åˆ›å»ºæœ€å°é…ç½®
            config = {
                'training': {
                    'algorithm': 'MAPPO',
                    'max_iterations': 2,
                    'rollout_steps': 10,
                    'n_envs': 1,
                    'device': 'cpu',
                    'eval_freq': 1,
                    'eval_episodes': 1,
                    'eval_seeds': [42],
                    'patience': 10
                },
                'mappo': {
                    'gamma': 0.99,
                    'gae_lambda': 0.95,
                    'clip_range': 0.2,
                    'n_epochs': 1,
                    'n_minibatches': 1,
                    'value_coef': 0.5,
                    'entropy_coef': 0.01,
                    'learning_rate': 1e-4,
                    'lr_decay': False,
                    'max_grad_norm': 0.5
                },
                'model': {
                    'shared_backbone': False,
                    'actor_hidden_sizes': [64, 64],
                    'critic_hidden_sizes': [128, 128],
                    'activation': 'relu',
                    'use_layer_norm': False
                },
                'env_config': {
                    'config_path': self.config_path,
                    'layers_path': 'layers.pkl',
                    'cache_dir': 'cache'
                },
                'output': {
                    'output_dir': 'test_output',
                    'save_models': False
                }
            }
            
            # åˆ›å»ºè®­ç»ƒå™¨
            trainer = MAPPOTrainer(config)
            
            # éªŒè¯è®­ç»ƒå™¨å±æ€§
            assert hasattr(trainer, 'policy'), "è®­ç»ƒå™¨ç¼ºå°‘policyå±æ€§"
            assert hasattr(trainer, 'buffer'), "è®­ç»ƒå™¨ç¼ºå°‘bufferå±æ€§"
            assert hasattr(trainer, 'env_runner'), "è®­ç»ƒå™¨ç¼ºå°‘env_runnerå±æ€§"
            
            # éªŒè¯ç½‘ç»œåˆå§‹åŒ–
            assert trainer.policy is not None, "ç­–ç•¥ç½‘ç»œæœªåˆå§‹åŒ–"
            
            # æ‰§è¡Œä¸€æ­¥è®­ç»ƒï¼ˆsmoke testï¼‰
            rollout_data = trainer.collect_rollouts(5)
            assert isinstance(rollout_data, dict), "rollout_dataä¸æ˜¯å­—å…¸ç±»å‹"
            assert 'n_steps' in rollout_data, "rollout_dataç¼ºå°‘n_steps"
            
            # æ‰§è¡Œç­–ç•¥æ›´æ–°
            train_stats = trainer.update_policy(rollout_data)
            assert isinstance(train_stats, dict), "train_statsä¸æ˜¯å­—å…¸ç±»å‹"
            assert 'policy_loss' in train_stats, "train_statsç¼ºå°‘policy_loss"
            
            self.validation_results['training_integration'] = True
            logger.info("âœ“ è®­ç»ƒå™¨é›†æˆéªŒè¯é€šè¿‡")
            return True
            
        except Exception as e:
            self.validation_results['training_integration'] = False
            logger.error(f"âœ— è®­ç»ƒå™¨é›†æˆéªŒè¯å¤±è´¥: {e}")
            return False
    
    def validate_model_forward(self) -> bool:
        """éªŒè¯æ¨¡å‹å‰å‘ä¼ æ’­"""
        logger.info("å¼€å§‹éªŒè¯æ¨¡å‹å‰å‘ä¼ æ’­")
        
        try:
            from src.rl.models.mappo_actor import MAPPOActor, MAPPOActorCritic
            from src.rl.models.mappo_critic import MAPPOCritic
            
            # æ¨¡æ‹Ÿæ•°æ®ç»´åº¦
            batch_size = 4
            n_agents = 6
            obs_dim = 68  # æ ¹æ®ç¯å¢ƒé…ç½®
            action_dim = 42
            global_state_dim = 100
            
            # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
            obs = torch.randn(batch_size, n_agents, obs_dim)
            action_mask = torch.ones(batch_size, n_agents, action_dim, dtype=torch.bool)
            # éšæœºå±è”½ä¸€äº›åŠ¨ä½œ
            action_mask[:, :, -5:] = False
            
            global_state = torch.randn(batch_size, global_state_dim)
            actions = torch.randint(0, action_dim, (batch_size, n_agents))
            
            # æµ‹è¯•Actor
            actor = MAPPOActor(obs_dim, action_dim)
            logits = actor(obs, action_mask)
            assert logits.shape == (batch_size, n_agents, action_dim), f"Actorè¾“å‡ºç»´åº¦é”™è¯¯: {logits.shape}"
            
            # éªŒè¯åŠ¨ä½œæ©ç ç”Ÿæ•ˆ
            masked_logits = logits[action_mask == False]
            assert torch.all(masked_logits < -1e8), "åŠ¨ä½œæ©ç æœªç”Ÿæ•ˆ"
            
            # æµ‹è¯•Critic
            critic = MAPPOCritic(global_state_dim)
            values = critic(global_state)
            assert values.shape == (batch_size,), f"Criticè¾“å‡ºç»´åº¦é”™è¯¯: {values.shape}"
            
            # æµ‹è¯•ActorCritic
            actor_critic = MAPPOActorCritic(obs_dim, action_dim, global_state_dim)
            test_actions, log_probs, test_values = actor_critic.get_action_and_value(
                obs, global_state, action_mask
            )
            assert test_actions.shape == (batch_size, n_agents), f"åŠ¨ä½œç»´åº¦é”™è¯¯: {test_actions.shape}"
            assert log_probs.shape == (batch_size, n_agents), f"å¯¹æ•°æ¦‚ç‡ç»´åº¦é”™è¯¯: {log_probs.shape}"
            assert test_values.shape == (batch_size,), f"ä»·å€¼ç»´åº¦é”™è¯¯: {test_values.shape}"
            
            # æµ‹è¯•evaluate_actions
            eval_log_probs, eval_values, entropy = actor_critic.evaluate_actions(
                obs, global_state, actions, action_mask
            )
            assert eval_log_probs.shape == (batch_size, n_agents), "è¯„ä¼°å¯¹æ•°æ¦‚ç‡ç»´åº¦é”™è¯¯"
            assert eval_values.shape == (batch_size,), "è¯„ä¼°ä»·å€¼ç»´åº¦é”™è¯¯" 
            assert entropy.shape == (batch_size, n_agents), "ç†µç»´åº¦é”™è¯¯"
            
            self.validation_results['model_forward'] = True
            logger.info("âœ“ æ¨¡å‹å‰å‘ä¼ æ’­éªŒè¯é€šè¿‡")
            return True
            
        except Exception as e:
            self.validation_results['model_forward'] = False
            logger.error(f"âœ— æ¨¡å‹å‰å‘ä¼ æ’­éªŒè¯å¤±è´¥: {e}")
            return False
    
    def run_all_validations(self) -> bool:
        """è¿è¡Œæ‰€æœ‰éªŒè¯"""
        logger.info("å¼€å§‹è¿è¡Œå®Œæ•´å…¼å®¹æ€§éªŒè¯")
        
        validations = [
            ('ç¯å¢ƒåŒ…è£…å™¨', self.validate_environment_wrappers),
            ('æ•°æ®æµ', self.validate_data_flow),
            ('æ¨¡å‹å‰å‘ä¼ æ’­', self.validate_model_forward),
            ('è®­ç»ƒå™¨é›†æˆ', self.validate_training_integration),
        ]
        
        all_passed = True
        for name, validation_func in validations:
            logger.info(f"\n{'='*50}")
            logger.info(f"éªŒè¯: {name}")
            logger.info(f"{'='*50}")
            
            passed = validation_func()
            if not passed:
                all_passed = False
        
        # è¾“å‡ºæ€»ç»“
        logger.info(f"\n{'='*50}")
        logger.info("éªŒè¯æ€»ç»“")
        logger.info(f"{'='*50}")
        
        for validation, result in self.validation_results.items():
            status = "âœ“" if result else "âœ—"
            logger.info(f"{status} {validation}: {'é€šè¿‡' if result else 'å¤±è´¥'}")
        
        if all_passed:
            logger.info("\nğŸ‰ æ‰€æœ‰å…¼å®¹æ€§éªŒè¯é€šè¿‡ï¼")
        else:
            logger.error("\nâŒ éƒ¨åˆ†éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯")
        
        return all_passed


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='å…¼å®¹æ€§éªŒè¯è„šæœ¬')
    parser.add_argument('--config', type=str, default='config.yaml',
                       help='ç¯å¢ƒé…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--test', type=str, 
                       choices=['wrappers', 'dataflow', 'models', 'training', 'all'],
                       default='all', help='æµ‹è¯•ç±»å‹')
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    # åˆ›å»ºéªŒè¯å™¨
    validator = CompatibilityValidator(args.config)
    
    # è¿è¡ŒæŒ‡å®šéªŒè¯
    if args.test == 'wrappers':
        success = validator.validate_environment_wrappers()
    elif args.test == 'dataflow':
        success = validator.validate_data_flow()
    elif args.test == 'models':
        success = validator.validate_model_forward()
    elif args.test == 'training':
        success = validator.validate_training_integration()
    else:  # all
        success = validator.run_all_validations()
    
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()